{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9c7285-2a68-45f8-9d0c-46136e2a3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8aec349-370d-4be1-905c-f3f319b235e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are an ai assstant that generate the one line defination for user', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='lame', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",\"you are an ai assstant that generate the one line defination for user\"),\n",
    "    (\"human\",\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "message=chat_template.format_messages(user_input=\"lame\")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a0780f-dd7f-4591-b27d-10dac38a1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee25d3c-87cb-4081-8211-978d553cf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493cbf56-f063-487e-ab26-599f05f11a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Lacking originality or interest; unimpressive.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-03-13T05:49:34.0247655Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3825816000, 'load_duration': 36258000, 'prompt_eval_count': 32, 'prompt_eval_duration': 1746000000, 'eval_count': 12, 'eval_duration': 2041000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c8385f50-e8a7-4c37-8053-e9fa29bc44ad-0', usage_metadata={'input_tokens': 32, 'output_tokens': 12, 'total_tokens': 44})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16497465-0439-4561-8fe4-e87917eac104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b4f14d-9f99-4e6d-bffd-3a359e90a03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are an AI potery generation, and you  must be genrate the poetry in 7 lines not more and not less', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Heaven', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are an AI potery generation, and you  must be genrate the poetry in 7 lines not more and not less\"),\n",
    "    (\"human\",\"{input_word}\")\n",
    "])\n",
    "\n",
    "message=chat_template.format_messages(input_word=\"Heaven\")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112abe0e-c912-45c6-90de-271286c245b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef65589d-38cd-42d5-b581-a43d5a58c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d08bcbe-570b-4171-b9fe-22990b05905b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ethereal skies above me shine\\nA canvas of blue, infinite design\\nSoftly whispers secrets to my soul\\nOf a world beyond, where love makes whole\\nIn this realm of peace, I find my nest\\nWhere worries fade like the setting west\\nAnd in stillness, my heart finds rest', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-03-13T05:50:14.6327644Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18597123100, 'load_duration': 50174500, 'prompt_eval_count': 43, 'prompt_eval_duration': 2274000000, 'eval_count': 63, 'eval_duration': 16270000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-76a18bd5-5848-4ccc-a628-1d984311faae-0', usage_metadata={'input_tokens': 43, 'output_tokens': 63, 'total_tokens': 106})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0a0c4e-dcfa-4704-81fe-6d99833f52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = chat_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61f6972-6d80-49e6-aac6-2f65389fd9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a short poem:\\n\\nMoonlight whispers secrets bright\\nShadows dance upon the wall tonight\\nA midnight breeze that stirs the trees\\nEchoes of memories that bring to knees\\nThe stars above, a twinkling sea\\nA world asleep, yet full of glee\\nIn this stillness, I am free.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input_word\":\"Lame\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa6c279b-23d4-4b83-b35c-c559dd578b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are ten recent research papers on Transformers:\n",
      "\n",
      "1. **\"Longformer: The Long Document Transformer\"**\n",
      "Search query: (\"longformer\" OR \"transformer architecture\") AND (\"long document\" OR \"sequence length\")\n",
      "2. **\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"** (Note: This is a classic paper, but still relevant to the topic)\n",
      "Search query: (\"bert\" OR \"deep bidirectional transformer\") AND (\"language understanding\" OR \"natural language processing\")\n",
      "3. **\"Attention Is All You Need\"**\n",
      "Search query: (\"attention mechanism\" OR \"transformer architecture\") AND (\"all you need\" OR \"sequence-to-sequence\")\n",
      "4. **\"Improving Language Understanding by Generative Models with Contrastive Divergence\"**\n",
      "Search query: (\"generative model\" OR \"contrastive divergence\") AND (\"language understanding\" OR \"natural language processing\")\n",
      "5. **\"Transformers for Image Processing: A Survey\"**\n",
      "Search query: (\"transformer architecture\" OR \"image processing\") AND (\"survey\" OR \"review\")\n",
      "6. **\"Efficient Transformers for Natural Language Processing\"**\n",
      "Search query: (\"efficient transformer\" OR \"nlp\") AND (\"natural language processing\" OR \"language understanding\")\n",
      "7. **\"Transformers in Vision: A Survey of Recent Advances\"**\n",
      "Search query: (\"transformer architecture\" OR \"vision\") AND (\"survey\" OR \"review\")\n",
      "8. **\"A New Perspective on Transformers for Sequence-to-Sequence Learning\"**\n",
      "Search query: (\"sequence-to-sequence learning\" OR \"transformer architecture\") AND (\"new perspective\" OR \"novel approach\")\n",
      "9. **\"Transformers with Multi-Head Attention and Positional Encoding for Text Classification\"**\n",
      "Search query: (\"multi-head attention\" OR \"positional encoding\") AND (\"text classification\" OR \"natural language processing\")\n",
      "10. **\"Improving Transformer Models with Layer Normalization and Weight Decay\"**\n",
      "Search query: (\"layer normalization\" OR \"weight decay\") AND (\"transformer architecture\" OR \"nlp\")\n",
      "\n",
      "Note that these search queries are just suggestions, and you may need to modify them slightly to get the most relevant results.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that suggests ten recent research papers on a given topic. \"\n",
    "               \"Since you do not have direct access to research databases, provide paper titles and corresponding search queries. \"\n",
    "               \"Users can use these queries on Google Scholar (https://scholar.google.com) or ArXiv (https://arxiv.org).\"),\n",
    "    (\"human\", \"{inputed_topic}\")\n",
    "])\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "chain = chat_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"inputed_topic\": \"Transformers\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb67b3f3-696d-4b4a-ba38-98949d55e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3d72a60-3502-4724-817b-386b7f5ca54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise summary of the text:\n",
      "\n",
      "Artificial intelligence (AI) is rapidly transforming industries worldwide by automating tasks and driving scientific breakthroughs. However, its increasing presence raises concerns about bias, transparency, and job displacement, sparking global discussions on responsible AI development to ensure it benefits humanity while minimizing risks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI-powered text summarization assistant. \n",
    "                  Your task is to generate concise, accurate, and well-structured summaries \n",
    "                  for the provided text while preserving key information and meaning. \n",
    "                  Ensure clarity, coherence, and readability in the summary.\"\"\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "chain = chat_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"text\": \"\"\" \n",
    "Artificial intelligence is transforming the world at an unprecedented pace. From automating mundane tasks to driving scientific discoveries, AI has become an integral part of various industries. As technology advances, the ethical implications of AI—such as bias, transparency, and job displacement—continue to spark global discussions. The future of AI depends on responsible development, ensuring that it benefits humanity while minimizing risks\n",
    "\"\"\"})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca214f7-7f44-424c-843d-f6a3d406175f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
